Project Agreement and Statement of Work
THIS PROJECT AGREEMENT AND STATEMENT OF WORK (this “Agreement”) is entered into by and between the undersigned Buyer and Service Provider as of the Effective Date. The Buyer and Service Provider are sometimes referred to collectively herein as the “Parties” and individually as a “Party”. All capitalized terms not defined in this Agreement have the meanings given to such terms in the Terms of Service Agreement (“Terms of Service”) available, unless the context requires otherwise. 


1.        BACKGROUND AND INITIAL OBLIGATIONS.


1.1        The “Buyer” is:
Martin Cenek
University of Alaska, Anchorage
290 Spirit Dr
Anchorage, AK 99508
E-mail: mcenek@alaska.edu


1.2        The “Service Provider” is:
        Masa Hu
        E-mail: yhu9@alaska.edu
        Rory Main
        E-mail: ramain@alaska.edu


1.3        The Project is:


The “Trash Classification Project” an automated drone that will take aerial images and make percentage calculations on the type of trash there is.


Delivery Date: April 19, 2017


Project Description:


“Trash Classification Project” is a semi-automated drone that will collect aerial images of piled garbage at dump sites in order to assess the percentage of trash that falls into the several classification categories


Key Assumptions:
* The drone will not fly in extreme conditions
* The drone will not fly in areas where lots of trees are present
* A user will know the proper procedures to start and end the automated flight path
* There will not be any unknown moving objects that could potentially collide with the drone
* There will be enough light to take images that can be processed
* There will not be any hostile threats to the drone
* The Garbage site will allow for the flight and image capturing the drones will be conducting
* The garbage site will allow for the user to walk into the area
* There will not be any animals that would interfere with the drone
* Drone flight will occur when the dump site’s public services are not being used
* The buyer will have knowledge on the usage of the drone as well as how to retrieve the information on it


1.4        Liabilities and Ownership


After the delivery date, the service providers are no longer obligated to continue to work on the project. Ownership of the product, as well as the code base created at the end of the delivery date will go to the Buyer. The cost of this product is $0.00. If the drone is damaged before the delivery date, it will be the responsibility of the service provider to fix the drone. Any damage the drone receives after the delivery date is the responsibility of the buyer. The service provider is only obligated to finish the first and second milestone. If all milestones are finished before the end of the delivery date, then the remaining time will be used to increase the accuracy rate of the classification program.


_____________________________
Buyer: Type Name, Signature, Date


_____________________________
Service Provider: Type Name, Signature, Date














Project Requirements/Specification


2. Objectives and Background:


[ 2.1 ]        The “Trash Classification Project” is a semi-automated drone that will collect aerial images of piled garbage at dump sites in order to assess the percentage of trash that falls into the several classification categories. It is required that the finished work can:
1.  Have an automated flight path in order to take a complete aerial image of a square area space without crashing into anything on the site.
2.  Use the aerial images captured on the flight to determine the percentage of trash classifications on the surface of the site.
3.  The drone will then store the captured images so that it can be retrieved manually
[ 2.2 ]        The recognition software will be tested and trained on photos in which the percentage of trash is known
[ 2.3 ]         The flight path automation will be tested for completeness of the imagery on the area, and the ability to fly without crashing
[ 2.3 ]        The first milestone is the following:
1. The drone should be able to fly a pre-specified flight path and take complete aerial images of an indoor area with a flat surface
2. The program should be able to take sample images and be able to classify them in the 4 categories of output and give a percentage for the presence of each category in the images
3. The accuracies of the classification should be provided with the output
4. The first milestone will be considered finished when the accuracy of the classification is above 60% and complete aerial images is achieved in the automated flight path
[ 2.4 ]         The second milestone is the following:
1. The drone should be able to fly outside at variable heights depending on its distance from the objects underneath it while taking complete aerial images of the area
2. The program should be able to take sample images and be able to classify them in the 4 categories of output and give a percentage for the presence of each category in the images
3. The second milestone will be considered finished when the accuracy of the classification is above 60%, and complete aerial images is achieved in the automated flight path
[ 2.5 ]        The third milestone is the following:
1. Complete automated flight without crashing based on the assumptions, and complete aerial images of an outdoor area that is used for trash collection
2. The classification algorithm should be able to use the retrieved images from the drone and output a classification percentage in the categories for the imagery
3. No classification accuracy will be given for the third milestone as the actual percentages are unknown
[ 2.6 ]        It is required that the first and second milestones be finished before the delivery date, but the last milestone is not required
[ 2.7 ]        It is the responsibility of the service provider to use any remaining time after the finishing of the second milestone to work on the third milestone
[ 2.8 ]        If the third milestone is not finished by the end of the delivery date, it is not the responsibility of the service provider to finish the third milestone


3. Automated Flight:


[ 3.01 ]        The drone will fly in a set pattern, periodically taking pictures before landing.
[ 3.02 ] A person does not need to be present for the automated flight path
[ 3.03 ]        A knowledgeable person must be present to begin the drone’s operation.
[ 3.04 ]        A knowledgeable person must be present to retrieve the drone and the data after the drone has finished its flight path
[ 3.05 ]        The pictures should be a full aerial view of the area that should be captured
[ 3.06 ]        The pictures should be usable for the classification algorithm to output an accuracy greater than 60%
[ 3.07 ]        The drone will not crash during the automated flight
[ 3.08 ]        The automated flight will surveil a square area
[ 3.09 ]        A .txt file will be created to explain the procedure for starting and ending the flight
[ 3.10 ] A manual override for the automated flight path will be available
[ 3.11 ]        There is a maximum flight area specific to the capabilities of the drone


4. Classification Program


[ 4.01 ]        Because of the nature of the software, the accuracy of the results cannot be confirmed without manual inspection of the trash
[ 4.02 ]        The image recognition software will be validated against a set of images to confirm that it meets an accuracy greater than 60%
[ 4.03 ]        During development and validation we will attempt to get as close to 100 as possible, however we hope to reach accuracies greater than 60%
[ 4.04 ]        The classification program will take the images as input, with all images stored in a single file
[ 4.05 ]        The classification program will output a .txt file that shows the results of the classification and store it in the parent directory of the program
[ 4.06 ]        The classification program will be separate from the drone
[ 4.07 ]        The classification program will be executable from a linux/windows computer
[ 4.08 ]        The classification program will use 4 categories to describe trash:
1. Cardboard 
2. Tree Matter {leaves, lawn grass, trees, branches, food}
3. Construction Waste {concrete, plywood, lumber, pipes, bars}
4. General Household Goods
[ 4.09 ]        Items in plastic bags would be considered household goods
[ 4.10 ]        A .txt file will be created to explain some of the strategies used for the classification program
[ 4.11 ]        A .txt file will be created to give credit to any open source programs used for this product
[ 4.12 ]        A .txt file will be created to explain how to use the program
[ 4.13 ]        The program will be executable from the cmd/terminal
[ 4.14 ]        There will not be any user interface to go with the program
[ 4.15 ]        The user will be responsible for supplying the program with the images
[ 4.16 ]        The user will be responsible to run the classification program
[ 4.17 ]        The user will be responsible for manipulating the output of the classification program
[ 4.18 ]        The user will be responsible for finding the accuracy of the classification program when used in the field


5. Expected Operations


[ 5.01 ]        A knowledgeable user will place the drone at a predetermined position and activate the automated procedure. 
[ 5.02 ]        The drone will proceed to safely patrol the designated area, periodically taking pictures before returning to the starting position. 
[ 5.03 ]        The user will retrieve the photos from the drone, and recover the drone
[ 5.04 ]        The photos can then be loaded onto a computer with the image recognition software
[ 5.05 ]        The images can be placed into a folder and that folder can be selected by the software
[ 5.06 ]        The software will then run before creating .txt file describing the percentages of trash identified in each image
[ 5.07 ]        The program will output a .txt file listing the picture, categories, and the corresponding percentages of trash identified in the picture


6. Errors
[ 6.01 ]        If there are no images supplied, the program will not run.
[ 6.02 ]        If the images are not of a good quality (IE: bad lighting, obscured objects), then the software might make highly inaccurate assessments.
[ 6.03 ]        It is the user’s responsibility to make sure the capturable images are not blocked from the drone’s view
[ 6.04 ]        It is the user’s responsibility to make sure the capturable images are well lit for use by the classification program
[ 6.05 ]        If the drone is not placed in the correct location, then the photos taken might not fully contain the subject.
[ 6.06 ]        If the drone is not placed in the correct location, then the automated route may cause it to hit walls, or other obstacles, potentially damaging the drone.
[ 6.07 ]        If the drone is not maintained, and if proper charging methods are not followed, the drone may not perform as intended.
[ 6.08 ]        If there are any obstacles that block the drone’s flight space, the automated procedure should not be run, or the drone risks damage